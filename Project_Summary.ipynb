{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c08825d-185b-4fc6-9d27-5cbfd4ed6cbe",
   "metadata": {},
   "source": [
    "# Project Report: News Article Classification (Fake/Real)\n",
    "\n",
    "**I. Introduction**\n",
    "In an era saturated with information, the ability to discern between genuine and fabricated news has become increasingly critical. \"Fake news\" can propagate misinformation, influence public opinion, and erode trust in traditional media. This project aims to address this challenge by developing a machine learning model capable of automatically classifying news articles as either fake or real. Leveraging Natural Language Processing (NLP) techniques, this system will analyze textual content to identify patterns indicative of authenticity, providing a valuable tool for content verification.\n",
    "\n",
    "**II. Abstract**\n",
    "This report details the development of a Fake News Classification system using a Logistic Regression model trained on TF-IDF vectorized textual data. The project involved loading and combining a comprehensive dataset of fake and real news articles, rigorous text preprocessing using NLTK to clean and standardize the content, and feature extraction via TF-IDF to convert text into numerical representations. A Logistic Regression classifier was then trained and evaluated on the processed data. The model achieved an accuracy of approximately 98.89%, demonstrating high precision, recall, and F1-scores for both classes. Furthermore, an interactive web application was built using Streamlit, allowing users to input news articles and receive real-time predictions along with confidence scores and explanations, showcasing a complete end-to-end machine learning solution.\n",
    "\n",
    "**III. Tools Used**\n",
    "**Python:** The primary programming language for all development.\n",
    "\n",
    "**Pandas:** Utilized for efficient data loading, manipulation, and combination of the news datasets.\n",
    "\n",
    "**NLTK (Natural Language Toolkit):** Employed for fundamental text preprocessing operations, specifically stop word removal.\n",
    "\n",
    "**Scikit-learn:** A comprehensive machine learning library used for:\n",
    "\n",
    "**TfidfVectorizer:** For converting raw text into numerical TF-IDF features.\n",
    "\n",
    "**train_test_split:** For dividing data into training and testing sets.\n",
    "\n",
    "**LogisticRegression:** The chosen classification algorithm for its effectiveness and interpretability.\n",
    "\n",
    "**accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report:** For robust model evaluation.\n",
    "\n",
    "**Matplotlib & Seaborn:** Used for data visualization, particularly for generating the confusion matrix heatmap to visually assess model performance.\n",
    "\n",
    "**Numpy:** For numerical operations, especially within data manipulation and vectorization.\n",
    "\n",
    "**pickle:** Python's standard library for serializing and deserializing Python object structures, used to save and load the trained model and vectorizer.\n",
    "\n",
    "**Streamlit:** An open-source app framework for machine learning engineers, used to create the interactive web-based demo for the classifier.\n",
    "\n",
    "**IV. Steps Involved in Building the Project**\n",
    "The project was developed following a structured machine learning pipeline:\n",
    "\n",
    "**Data Collection and Combination:**\n",
    "\n",
    "The project began by acquiring two distinct datasets, Fake.csv and True.csv, from Kaggle.\n",
    "\n",
    "Each dataset was loaded into a Pandas DataFrame, and a new label column was added (0 for fake, 1 for true).\n",
    "\n",
    "These two DataFrames were then concatenated to form a single, unified df_news dataset.\n",
    "\n",
    "Crucially, the combined dataset was shuffled to ensure random distribution of fake and real articles, preventing positional bias during subsequent data splitting. Initial data inspection confirmed no missing values, simplifying preprocessing.\n",
    "\n",
    "**Text Preprocessing (NLTK):**\n",
    "\n",
    "To prepare the textual data for analysis, the title and text columns were merged into a full_text column.\n",
    "\n",
    "A custom text cleaning function was applied to this column, performing several key operations: converting text to lowercase, removing URLs, HTML tags, punctuation, numbers embedded in words, and standard English stop words. This step significantly reduced noise and standardized the text.\n",
    "\n",
    "**Text Vectorization (TF-IDF):**\n",
    "\n",
    "Machine learning models require numerical input. Thus, the cleaned text was transformed into numerical features using the TfidfVectorizer.\n",
    "\n",
    "The TfidfVectorizer was configured to extract the top 10,000 most relevant features (max_features=10000) and to ignore terms appearing in fewer than 5 documents (min_df=5), focusing on words with significant discriminative power. The output was a sparse matrix X_tfidf.\n",
    "\n",
    "**Model Training (Logistic Regression):**\n",
    "\n",
    "The vectorized features (X_tfidf) and the corresponding labels (y) were split into training (80%) and testing (20%) sets using train_test_split. The stratify=y parameter ensured that the class distribution (fake/real) was maintained in both subsets.\n",
    "\n",
    "A LogisticRegression model, a robust linear classifier, was initialized with max_iter=1000 to ensure convergence, and then trained on the X_train and y_train data.\n",
    "\n",
    "**Model Evaluation:**\n",
    "\n",
    "The performance of the trained LogisticRegression model was rigorously evaluated on the unseen X_test dataset.\n",
    "\n",
    "Key metrics reported included overall Accuracy (0.9889), Precision, Recall, and F1-Score for both 'fake' and 'true' classes, all of which were approximately 0.99, indicating high model effectiveness.\n",
    "\n",
    "A Confusion Matrix was generated and visualized as a heatmap, providing a detailed breakdown of True Positives, True Negatives, False Positives, and False Negatives, clearly showing the minimal number of misclassifications.\n",
    "\n",
    "**Model Persistence:**\n",
    "\n",
    "To enable the deployment of the classifier, the trained LogisticRegression model and the fitted TfidfVectorizer were saved to disk using Python's pickle module (logistic_regression_model.pkl and tfidf_vectorizer.pkl). This ensures that the model can be loaded and used for predictions without requiring retraining.\n",
    "\n",
    "**Interactive Web Application (Streamlit Deployment):**\n",
    "\n",
    "An interactive web application (fake_news_app.py) was developed using the Streamlit framework.\n",
    "\n",
    "This application loads the saved model and vectorizer.\n",
    "\n",
    "It provides a user-friendly interface with a text area for users to input news articles.\n",
    "\n",
    "Upon user submission, the app preprocesses the text, vectorizes it using the loaded TfidfVectorizer, makes a prediction with the LogisticRegression model, and displays the classification outcome (FAKE or TRUE) along with confidence scores and a concise explanation. This creates a \"live web demo\" as required.\n",
    "\n",
    "**V. Conclusion**\n",
    "This project successfully developed a robust and highly accurate Fake News Classification system. By meticulously following a standard machine learning workflow—encompassing data preparation, text preprocessing, feature engineering, model training, evaluation, and deployment—a Logistic Regression model was developed that can reliably distinguish between fake and real news articles. The impressive accuracy (approx. 98.89%) and strong performance metrics highlight the model's efficacy. The creation of an interactive Streamlit application demonstrates practical deployment skills, making the model accessible and usable. This project provides valuable experience in Natural Language Processing and supervised learning, crucial for understanding and combating misinformation in digital media."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
